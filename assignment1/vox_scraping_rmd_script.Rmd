---
title: "Coding 2 - Assignment 1 - Scraping Vox.com"
author: "Cosmin Catalin Ticu"
date: "21/11/2020"
output:   
  prettydoc::html_pretty:
    theme: cayman
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(rvest)
library(moments)
library(data.table)
```

## The website of interest was chosen as [Vox.com](https://www.vox.com), one of the most popular liberal media outlets in the United States

The following function facilitates the gathering of information from one single page. The measures of interest were deemed as title, author, date and link.

```{r}
get_one_page_from_vox <- function(my_url_vox) {
  
  t <- read_html(my_url_vox)
  
  boxes <- t %>%html_nodes('.c-entry-box--compact')
  
  box_dfs <- lapply(boxes, function(x){
    
    tl <- list()
    
    tl[['title']] <- x %>% 
      html_nodes('.c-entry-box--compact__title') %>% 
      html_text()
    
    tl[['author(s)']] <- x %>% 
      html_nodes('.c-byline__author-name') %>% 
      html_text() %>% 
      toString() # was needed to stop multiple authors showing individually in the list
    
    # This code would have also worked.
    # However, it would have set non-registered authors as "NA" rather than
    # the default used by Vox which is "Vox Staff".
    ###
    # tl[['author']] <- x %>% 
    # html_nodes('.c-byline__item') %>% 
    # html_nodes('a') %>% 
    # html_text()
    ###
    
    tl[['timestamp']] <- x %>% html_nodes('time.c-byline__item') %>% 
      html_attr('datetime') %>% 
      strtrim(10) %>% # precise time not of interest
      as.Date()
    
    tl[['link']] <- x %>% 
      html_nodes('.c-entry-box--compact__image-wrapper') %>% 
      html_attr('href')
    
    return(tl)
    
  })
  
  df <- rbindlist(box_dfs, fill = T) 
  # for inconsistencies across missing values, the fill was set to TRUE
  return(df)
  
}
```

The following function applies a searchterm and a number of pages to download to the first function in an iterative way by using 'lapply'. The 'rbindlist' statement is used to compile the resulting lists into a data frame.

```{r}
# example search term "ionel"
# example pages to download "5"

get_vox_data <- function(searchterm, pages_to_download) {
  
  # concatenate the search terms together according to URL
  searchterm <- gsub(' ','+',searchterm)
  
  # create links; works also for any number of pages inputted
  if (pages_to_download == 1){
  
    links_to_get <- paste0('https://www.vox.com/search?&q=',
                           searchterm)
    
  }
  
  else{
    
    links_to_get <- c(paste0('https://www.vox.com/search?&q=',
                             searchterm),
                      paste0('https://www.vox.com/search?&page=',
                             2:pages_to_download,
                             '&q=',
                             searchterm))
    
  }
  
  ret_df <- 
    rbindlist(lapply(links_to_get, get_one_page_from_vox))
  
  return(ret_df)
  
}
```

The final output of this function can be observed in the example snippet below and the table at the bottom of the page that it subsequently produces.

```{r, message=FALSE, warning=FALSE}
kukus <- get_vox_data('obama trump birth certificate',5) 
knitr::kable(kukus)
```

